% !TeX root = ../BA_main_englisch.tex
% !TeX spellcheck = en_GB
In Section \ref{n_5_ml} we encountered a conceptional problem regarding using the MSE as a loss function, where a low MSE score does not necessarily imply a large work output.
In the following we train a model on the average extracted work $W$ directly for comparison.

For $\Delta \mathrm{T} = 1$, we train a bidirectional LSTM using this approach, giving a work output of $W_{test} = 1.51$ and efficiency $\eta_{test} = 91.0 \%$.
This is below the performance of the model trained on the MSE loss.
A possible reason for this difference is that while each training sample for the MSE loss is optimised individually, the work loss maximises the output of multiple drive samples at the same time because of the batch training used in this work (Appendix \ref{training}).